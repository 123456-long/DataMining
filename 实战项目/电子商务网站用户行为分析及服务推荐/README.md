# 电子商务网站用户行为分析及服务推荐
- 背景
	- 随着互联网和信息技术的迅速发展，电子商务、网上服务与交易等网络业务越来越普及，大量的信息聚集起来，形成了“海量”信息。用户想要从海量信息中快速准确地寻找到自己感兴趣的信息已经变得越来越难了，在电子商务领域尤其如此。因此，信息过载的问题已经成为互联网技术中的一个重要难题。
	- 为了解决这个问题，搜索引擎诞生了，例如谷歌、百度。搜索引擎在一定程度上缓解了信息过载问题，用户通过输入关键字，搜索引擎就会返回给用户与输入的关键字相关的信息。可以想象，没有搜索引擎，用户一个网站一个网站去寻找信息那是一种怎样的局面。但是，搜索引擎也有很多无法解决的用户需求，例如用户想找到准确描述自己需求的关键词时，搜索引擎就无能为力了，毕竟它只是搜索而非理解。
	- 与搜索引擎不同，推荐系统不需要用户提供明确的需求，而是通过分析用户的历史行为，从而主动向用户推荐能够满足他们兴趣和需求的信息。因此，对于用户而言，推荐系统和搜索引擎是两个互补的工具。搜索引擎满足有明确目标用户的需求，而推荐系统帮助用户发现其感兴趣的内容。
	- 在电子商务领域推荐技术起到如下作用
		- 帮助用户找到其感兴趣的物品，节省用户时间，提升用户体验；
		- 提高用户对电子商务网站的忠诚度，如果推荐系统能够准确发现用户的兴趣点，并将合适的资源推荐给用户，用户就会对电子商务网站产生依赖，从而建立稳定的企业忠实顾客群。（这点淘宝是做得不错的）
- 目标
	- 本案例的研究对象是北京某家法律网站，它是一家电子商务类的大型法律资讯网站，致力于为用户提供丰富的法律信息与专业咨询服务，并为律师与律师事务所提供卓有成效的互联网整合营销解决方案。随着其网站访问量增大，数据信息量也在大幅增加。用户在面对大量信息时无法从中获得自己需要的信息，对信息的使用效率越来越低。这种浏览大量无关信息的过程，使用户需要花费大量时间才能找到自己需要的信息，从而使得用户不断流失，给企业造成巨大的损失。
	- 为了能够更好地满足用户需求，依据其网站海量的数据，研究用户的兴趣偏好，分析用户的需求和行为，发现用户的兴趣点，从而引导用户发现自己的信息需求，将网页准确推荐给所需用户，帮助用户发现感兴趣但很难发现的网页信息。为用户提供个性化的服务，并且建立网站与用户之间的密切关系，让用户对推荐系统产生依赖，从而建立忠实顾客群，实现客户链式反应增值，提高消费满意度。
	- 目前网站已有一些热点推荐，但不足以满足用户需求。当用户访问网站页面时，系统会记录用户访问网站的日志。包括IP（已做数据脱敏处理）、用户访问时间、访问内容等记录。
	- 实现如下目标
		- 按地域研究用户访问时间、访问内容和访问次数等分析主题，深入了解用户对访问网站的行为和目的及关心的内容。
		- 借助大量用户访问记录，发现用户的访问行为习惯，对不同需求的用户进行相关的服务页面的推荐。
- 分析
	- 本案例的目标是对用户进行推荐，即以一定的方式将用户与物品之间（本案例指网页）之间建立联系。为了更好地帮助用户从海量的数据中快速发现感兴趣的网页，在目前相对单一的推荐系统上进行补充，采用**协同过滤算法**进行推荐。
	- 由于用户访问网站的数据记录很多，如果对数据不进行分类处理，对所有记录直接采用推荐系统进行推荐，必然出现如下问题。
		- 数据量太大意味着物品数与用户数很多，在模型构建用户与物品的稀疏矩阵时，出现设备内存空间不够的情况，并且模型计算需要消耗大量的时间。
		- 用户区别很大，不同的用户关注的信息不一样，因此，即使能够得到推荐结果，其推荐效果也不会很好。
	- 为了避免出现上述问题，需要进行分类处理与分析。正常的情况下，需要对用户的兴趣爱好以及需求进行分类。因为在用户访问记录中，没有记录用户访问网页时间的长短，因此不容易判断用户的兴趣爱好。因此，本文根据用户浏览的网页信息进行分类处理，主要采用以下方法处理：以用户浏览网页的类型进行分类，然后对每个类型中的内容进行推荐。
	- 整个分析过程可以分为如下过程
		- 从系统中获取用户访问网站的原始记录。
		- 对数据进行多维度分析，包括用户访问内容，流失用户分析以及用户分类等分析。
		- 对数据进行预处理，包含数据去重、数据变换和数据分类等处理过程。
		- 以用户访问html后缀的网页为关键条件，对数据进行处理。
		- 对比多种推荐算法进行推荐，通过模型评价，得到比较好的智能推荐模型。通过模型对样本数据进行预测，获得推荐结果。
- 处理过程
	- 数据获取
		- 因为本案例是以协同过滤算法为主导，其他的推荐算法为辅助，而协同过滤算法的特点就是通过历史数据找到相似的用户或者网页。因此，在数据抽取的过程中，尽可能选择大量的数据，这样可以降低推荐结果的随机性，提高推荐结果的准确性，能更好地发掘长尾网页中用户感兴趣的网页。
		- 以用户的访问时间为条件，选取三个月内（2015-02-21~2015-04-29）用户的访问数据作为原始数据集。每个地区的用户访问习惯以及兴趣爱好存在差异性，本案例抽取广州地区数据进行分析，共837453条记录，所含属性见数据集。
		- 虽然这个数据量对于“大数据”这个概念，并不算大，，但是这个数据量对于低配电脑还是颇有压力的。因此，本案例的处理过程，真正的、初步的体现了用Python处理大数据的味道。
		- 处理过程为：建立数据库--->导入数据（导入方法自行查阅，一般使用mysql的source命令）--->搭建Python的数据库操作环境--->对数据进行分析--->建立模型。其中，数据库为mariaDB（免费版本的MySQL）。安装数据库后导入案例的原始数据文件raw.sql就成功配置好了数据库平台。
			- 可能出现如下错误
				- ERROR 2005 (HY000): Unknown MySQL server host '10997107101114' (0)	
				- ERROR:
				- Can't connect to the server
				- No connection. Trying to reconnect...
			- 解决方法
				- 修改my.ini文件中的max_allowed_packet = 640M，可能大小超过了
				- 命令行使用如下命令
					- mysql -u root -p 创建的数据库名 <C:\Users\16957\Desktop\data.sql --default-character-set=utf8
					- 在等待漫长的时间后成功导入了837450条数据
		- 在Python中，pandas可以利用read_sql()读取数据库，但是依赖于SQLAlchemy，而SQLAlchemy依赖于pymysql，所以需要安装这两个依赖包。（pip安装即可）
		- 在安装完成后，可以通过Python连接到数据库。为了方便处理数据，利用pandas。然而，pandas在读取数据时（无论什么格式，csv，tsv，xls，sql），都是将全部数据读入内存，因此在数据量大的时候，这是难以实现的。（因为内存容量是不够的）幸运的是，pandas提供了chunksize参数，可以让我们分块读取大数据文件。具体见github代码见 访问数据库.py。
	- 数据探索
		- 网页类型分析
			- 作为第一步，针对原始数据中用户点击的网页类型进行统计，网页类型是指“网址类型”的前三位数字（本身有6-7位数字）。前面已经提到过，此处处理的要义在于“分块进行”，必要时可以使用多线程或者分布式计算。
			- 见 数据探索.py
				- ![](https://img-blog.csdnimg.cn/20190212125026355.png)
			- 可以发现点击“咨询相关”（网页类型101的）最多，其次是“其他类型”（网页类型199的），然后是“知识相关”。可以得到用户点击页面类型的排行榜为：咨询相关、知识相关、其他方面的网页、法规（301）、律师相关（102）。可以初步得出相对于长篇的知识，用户更加偏向于查看咨询或者进行咨询。
			- 对**咨询类别**内部进行统计分析，可以发现咨询内容页（101003）记录最多，其次是咨询列表页（101002）和咨询首页（101001）。综合上述初步结论，可以得出用户都喜欢通过浏览问题的方式找到自己需要的信息而不是以提问的方式或者查看长篇知识的方式得到所需信息。
			- 对**知识相关**进行分析，因为只有一种类型（107001），所以利用网址进行分类，主要利用正则表达式进行匹配。代码见 数据探索.py
				- ![](https://img-blog.csdnimg.cn/20190212162757127.png)
			- 对**其他方面**进行分析，其中网址带有“?”的占了32%左右，其他咨询相关与法规专题占比达到43%，地区和律师占比26%。在网页分类中，已经存在了律师等分类，为什么还会存在于其他类别中呢，这是由于网页地址没有匹配到这种格式。
			- 通过对这三种分析，用户的一般使用情况为：咨询内容页、知识内容页、法规专题页、咨询经验（在线咨询页）。因此，在后续分析中选取占比最多的两类（咨询内容页和知识内容页）进行模型分析。
		- 点击次数分析
			- 统计分析原始数据用户浏览网页次数（以“真实IP”区分）的情况，见上面代码。
				- ![](https://img-blog.csdnimg.cn/20190212183327523.png)
			- 可以看出，大约80%的用户（不超过3次）只提供了大约30%的浏览量（几乎满足二八定律）。在数据中，点击次数最大值为42790次，对其进行分析，发现是律师的浏览信息（通过律师助手进行判断）。
			- 对浏览次数达到7次以上的情况进行分析，大部分用户浏览8-100次。
			- 对浏览次数为1次的用户进行分析，问题咨询页占比78%，知识页占比15%，而且这些记录基本上是通过搜索引擎进入的。由此可以猜测两种可能：1）用户为流失用户，没有找到自己的需要；2）用户找到了自己想要的信息，因此直接退出。可以归结为跳出率，需要对这些网页进行针对用户的个性化推荐，帮助用户发现其感兴趣或者需要的网页，
			- 针对点击一次的用户浏览的网页进行统计分析，发现排名靠前的都是知识与咨询页面，因此可以猜测大量用户的关注都在知识和咨询上。
		- 网页排名
			- 通过查看各个页面的点击率，和通过搜索引擎进入后翻页的概率，从而决策。
	- 数据预处理
		- 数据清洗
			- 去除无用数据。 
		- 数据变换
			- 识别翻页，对翻页进行还原。
		- 属性规约
			- 本案例需要的是用户与用户访问的网页，因此，删除其他属性。
	- 数据挖掘建模
		- 模型构建
			- 实际使用，一般多种推荐方法进行组合，得到推荐结果，组合可以并行或者串行，本案例采用并行组合。
			- 此部分数学逻辑较多，不一一赘述，可以查看代码。主要是协同过滤算法的代码。
	- 后续处理
		- 对婚姻知识类建模评价。
- 补充说明
	- 案例参考书《Python数据分析与挖掘实战》
	- 与原书有借鉴，但是较大改动代码
	- 修复了原书一些旧版本代码错误
	- 具体数据集和代码可以查看我的Github，欢迎star或者fork